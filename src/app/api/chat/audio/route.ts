import { NextRequest, NextResponse } from "next/server";
import { getAuthenticatedUser } from "@/lib/auth";

export const runtime = "nodejs";

// Fun√ß√£o para transcrever √°udio usando API externa
async function transcribeAudio(audioBlob: Blob, audioType: string): Promise<string | null> {
  try {
    // Tentar usar AssemblyAI primeiro (gratuito at√© 5 horas/m√™s)
    const assemblyApiKey = process.env.ASSEMBLYAI_API_KEY;
    
    if (assemblyApiKey) {
      return await transcribeWithAssemblyAI(audioBlob, audioType, assemblyApiKey);
    }
    
    // Tentar usar Deepgram como alternativa (gratuito at√© 12.000 minutos/m√™s)
    const deepgramApiKey = process.env.DEEPGRAM_API_KEY;
    if (deepgramApiKey) {
      return await transcribeWithDeepgram(audioBlob, audioType, deepgramApiKey);
    }
    
    // Tentar usar Google Speech-to-Text como √∫ltima op√ß√£o
    const googleApiKey = process.env.GOOGLE_SPEECH_API_KEY;
    if (googleApiKey) {
      return await transcribeWithGoogle(audioBlob, audioType, googleApiKey);
    }
    
    console.warn("Nenhuma API de transcri√ß√£o configurada. Configure ASSEMBLYAI_API_KEY, DEEPGRAM_API_KEY ou GOOGLE_SPEECH_API_KEY");
    return null;
  } catch (error) {
    console.error("Erro ao transcrever √°udio:", error);
    return null;
  }
}

// Transcri√ß√£o usando AssemblyAI (recomendado - gratuito at√© 5h/m√™s)
async function transcribeWithAssemblyAI(audioBlob: Blob, audioType: string, apiKey: string): Promise<string | null> {
  try {
    // Upload do √°udio
    const uploadResponse = await fetch("https://api.assemblyai.com/v2/upload", {
      method: "POST",
      headers: {
        authorization: apiKey,
      },
      body: audioBlob,
    });
    
    if (!uploadResponse.ok) {
      throw new Error("Falha ao fazer upload do √°udio");
    }
    
    const { upload_url } = await uploadResponse.json() as { upload_url: string };
    
    // Iniciar transcri√ß√£o
    const transcriptResponse = await fetch("https://api.assemblyai.com/v2/transcript", {
      method: "POST",
      headers: {
        authorization: apiKey,
        "content-type": "application/json",
      },
      body: JSON.stringify({
        audio_url: upload_url,
        language_code: "pt",
      }),
    });
    
    if (!transcriptResponse.ok) {
      throw new Error("Falha ao iniciar transcri√ß√£o");
    }
    
    const { id } = await transcriptResponse.json() as { id: string };
    
    // Polling para obter resultado
    let transcript = null;
    let attempts = 0;
    const maxAttempts = 60; // 60 tentativas (5 minutos m√°ximo)
    
    while (!transcript && attempts < maxAttempts) {
      await new Promise((resolve) => setTimeout(resolve, 5000)); // Aguardar 5 segundos
      
      const statusResponse = await fetch(`https://api.assemblyai.com/v2/transcript/${id}`, {
        headers: {
          authorization: apiKey,
        },
      });
      
      if (!statusResponse.ok) {
        throw new Error("Falha ao verificar status da transcri√ß√£o");
      }
      
      const statusData = await statusResponse.json() as { status: string; text?: string; error?: string };
      
      if (statusData.status === "completed") {
        transcript = statusData.text;
      } else if (statusData.status === "error") {
        throw new Error(statusData.error || "Erro na transcri√ß√£o");
      }
      
      attempts++;
    }
    
    return transcript || null;
  } catch (error) {
    console.error("Erro na transcri√ß√£o AssemblyAI:", error);
    return null;
  }
}

// Transcri√ß√£o usando Deepgram (alternativa - gratuito at√© 12k minutos/m√™s)
async function transcribeWithDeepgram(audioBlob: Blob, audioType: string, apiKey: string): Promise<string | null> {
  try {
    const response = await fetch("https://api.deepgram.com/v1/listen?language=pt-BR&punctuate=true", {
      method: "POST",
      headers: {
        Authorization: `Token ${apiKey}`,
        "Content-Type": audioType,
      },
      body: audioBlob,
    });
    
    if (!response.ok) {
      throw new Error("Falha na transcri√ß√£o Deepgram");
    }
    
    const responseData: any = await response.json();
    const transcript = responseData?.results?.channels?.[0]?.alternatives?.[0]?.transcript;
    return transcript || null;
  } catch (error) {
    console.error("Erro na transcri√ß√£o Deepgram:", error);
    return null;
  }
}

// Transcri√ß√£o usando Google Speech-to-Text (alternativa)
async function transcribeWithGoogle(audioBlob: Blob, audioType: string, apiKey: string): Promise<string | null> {
  try {
    // Converter blob para base64
    const arrayBuffer = await audioBlob.arrayBuffer();
    const base64Audio = Buffer.from(arrayBuffer).toString("base64");
    
    const response = await fetch(
      `https://speech.googleapis.com/v1/speech:recognize?key=${apiKey}`,
      {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          config: {
            encoding: "WEBM_OPUS",
            sampleRateHertz: 48000,
            languageCode: "pt-BR",
          },
          audio: {
            content: base64Audio,
          },
        }),
      }
    );
    
    if (!response.ok) {
      throw new Error("Falha na transcri√ß√£o Google");
    }
    
    const data = await response.json() as { results?: Array<{ alternatives?: Array<{ transcript?: string }> }> };
    
    const transcript = data.results?.[0]?.alternatives?.[0]?.transcript;
    return transcript || null;
  } catch (error) {
    console.error("Erro na transcri√ß√£o Google:", error);
    return null;
  }
}

// Processar mensagem usando o mesmo sistema do chat principal
async function processMessageWithDobby(message: string, userId: number, authCookie?: string): Promise<string> {
  // Chamar a API do chat normal para processar a mensagem
  // Isso garante que o Dobby entenda o √°udio da mesma forma que entende texto
  try {
    const baseUrl = process.env.NEXT_PUBLIC_BASE_URL || "http://localhost:3000";
    const headers: Record<string, string> = {
      "Content-Type": "application/json",
    };
    
    // Adicionar cookie de autentica√ß√£o se dispon√≠vel
    if (authCookie) {
      headers["Cookie"] = authCookie;
    }
    
    const response = await fetch(`${baseUrl}/api/chat`, {
      method: "POST",
      headers,
      body: JSON.stringify({ message }),
    });
    
    if (response.ok) {
      const data = await response.json() as { message: string };
      return data.message;
    }
  } catch (error) {
    console.error("Erro ao processar mensagem via chat:", error);
  }
  
  // Fallback: retornar mensagem padr√£o se n√£o conseguir processar
  return `Recebi seu √°udio! Como posso ajud√°-lo? Posso buscar informa√ß√µes sobre:\n\n` +
    `üìö Base de conhecimento\n` +
    `üìÅ Arquivos e downloads\n` +
    `üé´ Tickets e chamados\n` +
    `üìÖ Agenda e compromissos\n` +
    `üîê Senhas e credenciais\n` +
    `üìù Hist√≥rico e atualiza√ß√µes\n` +
    `üìä Estat√≠sticas do sistema\n` +
    `üìà Relat√≥rios detalhados\n\n` +
    `Fa√ßa uma pergunta espec√≠fica e eu buscarei as informa√ß√µes para voc√™!`;
}

// Fun√ß√£o para processar √°udio e entender a inten√ß√£o
async function processAudioIntent(audioFile: File, transcript: string | null, userId: number, authCookie?: string): Promise<string> {
  let finalTranscript = transcript;
  
  // Se n√£o temos transcri√ß√£o do cliente, tentar transcrever usando API externa
  if (!finalTranscript || finalTranscript.trim().length === 0) {
    console.log("[chat:audio] Tentando transcrever √°udio com API externa...");
    const audioBlob = await audioFile.arrayBuffer().then(buf => new Blob([buf], { type: audioFile.type }));
    finalTranscript = await transcribeAudio(audioBlob, audioFile.type);
    
    if (finalTranscript) {
      console.log("[chat:audio] Transcri√ß√£o obtida:", finalTranscript.substring(0, 100));
    } else {
      console.log("[chat:audio] N√£o foi poss√≠vel transcrever o √°udio");
    }
  }
  
  // Se temos transcri√ß√£o (do cliente ou da API), usar ela para entender a inten√ß√£o atrav√©s do sistema do Dobby
  if (finalTranscript && finalTranscript.trim().length > 0) {
    return await processMessageWithDobby(finalTranscript.trim(), userId, authCookie);
  }
  
  // Se n√£o temos transcri√ß√£o, retornar mensagem gen√©rica mas √∫til
  return `Recebi seu √°udio, mas n√£o consegui transcrev√™-lo automaticamente. Por favor:\n\n` +
    `‚Ä¢ Configure uma API de transcri√ß√£o (AssemblyAI, Deepgram ou Google Speech-to-Text)\n` +
    `‚Ä¢ Ou use um navegador compat√≠vel com transcri√ß√£o de voz (Chrome, Edge ou Opera)\n` +
    `‚Ä¢ Ou digite sua pergunta diretamente\n\n` +
    `Posso ajud√°-lo com:\n` +
    `üìö Base de conhecimento\n` +
    `üìÅ Arquivos e downloads\n` +
    `üé´ Tickets e chamados\n` +
    `üìÖ Agenda e compromissos\n` +
    `üîê Senhas e credenciais\n` +
    `üìù Hist√≥rico e atualiza√ß√µes\n` +
    `üìä Estat√≠sticas do sistema\n` +
    `üìà Relat√≥rios detalhados`;
}

export async function POST(req: NextRequest) {
  const user = await getAuthenticatedUser();
  if (!user) {
    return NextResponse.json({ error: "N√£o autenticado" }, { status: 401 });
  }

  try {
    const formData = await req.formData();
    const audioFile = formData.get("audio") as File | null;

    if (!audioFile) {
      return NextResponse.json({ error: "√Åudio n√£o fornecido" }, { status: 400 });
    }

    // Verificar tamanho do arquivo (m√°ximo 10MB)
    if (audioFile.size > 10 * 1024 * 1024) {
      return NextResponse.json({ error: "√Åudio muito grande. M√°ximo 10MB." }, { status: 400 });
    }

    // Verificar tipo MIME
    if (!audioFile.type.startsWith("audio/")) {
      return NextResponse.json({ error: "Arquivo n√£o √© um √°udio v√°lido" }, { status: 400 });
    }

    // Pegar transcri√ß√£o se dispon√≠vel
    const transcript = formData.get("transcript") as string | null;
    
    // Pegar cookie de autentica√ß√£o da requisi√ß√£o
    const authCookie = req.headers.get("cookie") || undefined;
    
    // Processar √°udio e gerar resposta do Dobby
    const message = await processAudioIntent(audioFile, transcript, user.id, authCookie);
    
    // Tentar obter transcri√ß√£o se n√£o tivermos do cliente
    let finalTranscript = transcript;
    if (!finalTranscript) {
      const audioBlob = await audioFile.arrayBuffer().then(buf => new Blob([buf], { type: audioFile.type }));
      finalTranscript = await transcribeAudio(audioBlob, audioFile.type);
    }
    
    return NextResponse.json({
      message,
      audioReceived: true,
      audioSize: audioFile.size,
      audioType: audioFile.type,
      transcript: finalTranscript || transcript || null,
      transcribed: !!finalTranscript,
    });
  } catch (error) {
    console.error("[chat:audio:POST]", error);
    return NextResponse.json(
      { error: "Erro ao processar √°udio" },
      { status: 500 }
    );
  }
}

